#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Path: signature-reader/main.py

from sys import argv
from os import system
from typing import Final, Dict
from datetime import datetime as dt
from gspread import service_account


OUT_PATH: Final[str]            = './out'
G_DRIVE_PATH: Final[str]        = 'OrgStructure'
HTML_TEMPLATE_PATH: Final[str]  = './templates/template.html'

'''
Here we store a dict of keys to parse from the Slovak language to standard
English. The original database include Slovak keys, and, for brevity, we
would like to use the same keys in the English language. Note: these are not
dynamically defined, but hardcoded. We would need to use a specialized tool to
carry the translation for us - in order to be dynamic. That is not crucial to the
execution of the program.
'''

KEYS_TO_PARSE_FROM_SLOVAK: Final[Dict] = {
    'Pracovná pozícia': 'position',
    'Pracovník': 'name',
    'Titul': 'academic_title',
    'Mobil číslo': 'phone',
    'Mail': 'email',
    'Firma do podpisu': 'company',
    'Sídlo firmy': 'street'
}

def main():
    # for time analysis [optional]
    start_time: dt = dt.now() 

    # remove all files in the output directory
    system(f'sudo rm {OUT_PATH}/*') 

    '''
    We create a service account and authorize it to access the Google Drive from within
    the credentials.json file, that is generated by the Google Cloud Platform.
    We open the initial sheet and format the data to a list, i.e. a list of dicts containing
    each row of the sheet.
    '''

    service_client = service_account(filename='credentials.json')
    sheet = service_client.open(G_DRIVE_PATH).sheet1
    data: list = format_data(sheet)

    '''
    We have a template HTML file, with so-called "placeholders". These placeholders
    start with a '#' character. We read the data obtained from the database and 
    replace the placeholders with respective data. Then, we export a new HTML file
    with the data with a name of the file the same as the name variable within the row.
    '''

    for person in data:
        file_name: str = person['name'].strip().replace(' ', '-').lower() + '.html'

        for t_line in open(HTML_TEMPLATE_PATH):
            t_line = t_line.strip()
            
            '''
            Here we replace the 'NAME' placeholder with the actual data:
            `Title. Name SURNAME`
            Furthermore, some people may not have an academic title, so we check if
            the value is \'null\' literal. If it is, we replace the placeholder with
            an empty string.
            ------------------------------------------------------------------------
            The job position, company name, phone, e-mail are parsed without
            any extra modifications.
            ------------------------------------------------------------------------
            The city, street parameters are parsed with the following rules:
            The value may be an empty string or a dash character, which will indicate
            an empty value. For that, we use the try/except block. If the exception 
            is not raised, we replace the placeholder with the value in the desired 
            format.
            ------------------------------------------------------------------------
            Lastly, we write each line to the output files with the names computed.
            '''

            if t_line == '#NAME':
                raw_name: str = person['name'].strip().split(' ')
                academic_title: str = person['academic_title'].strip()

                title: str = ''
                if academic_title != 'null':
                    title = academic_title + ' '

                t_line = f'{title}{raw_name[0]} {raw_name[-1].upper()}'
            
            elif t_line == '#POSITION':
                t_line = person['position']

            elif t_line == '#COMPANY':
                t_line = person['company']

            elif t_line == '#PHONE':
                t_line = person['phone']

            elif t_line == '#E-MAIL':
                t_line = person['email']

            elif t_line == '#STREET':
                try:
                    t_line = person['street'].split(',')[0].strip()
                except IndexError:
                    t_line = ''
            elif t_line == '#CITY':
                try:
                    t_line = person['street'].split(',')[1].strip()
                except IndexError:
                    t_line = ''

            with open(f'{OUT_PATH}/{file_name}', 'a') as f:
                f.write(t_line + '\n')

    # Debug flag [optional]
    if '--debug' in argv or '-d' in argv:
        print(f'The execution took: '
            f'{round((dt.now() - start_time).total_seconds(), 2)} '
            f'seconds.\nInvoked by: \t\'--debug | -d\'')


'''
Function that formats the data - i.e. converts the data to a list of dicts,
where we parse the Slovak keys to standard English keys, using only the desired
keys. The original structure of the data is preserved - list of dicts.
'''

def format_data(sh) -> dict:
    buff: list = []
    for row in sh.get_all_records():
        temp: dict = {}
        for key in KEYS_TO_PARSE_FROM_SLOVAK.keys():
            temp[KEYS_TO_PARSE_FROM_SLOVAK[key]] = row[key]
        buff.append(temp)
    return buff


if __name__ == '__main__':
    main()
